# ðŸ”’ GuÃ­a de Backup - Finanzas Pro

Esta guÃ­a explica cÃ³mo configurar backups automÃ¡ticos diarios de tu base de datos con subida opcional a la nube.

## ðŸ“‹ CaracterÃ­sticas

- âœ… **Backup diario automÃ¡tico** (horario configurable)
- âœ… **RetenciÃ³n de 7 dÃ­as** (configurable)
- âœ… **CompresiÃ³n gzip** para ahorrar espacio
- âœ… **Subida automÃ¡tica a la nube** (Google Drive, Dropbox, S3, etc.)
- âœ… **Limpieza automÃ¡tica** de backups antiguos (local y en la nube)
- âœ… **RestauraciÃ³n fÃ¡cil** con menÃº interactivo
- âœ… **DetecciÃ³n automÃ¡tica** del contenedor de PostgreSQL

## ðŸš€ ConfiguraciÃ³n RÃ¡pida

### 1. Hacer el script ejecutable

```bash
chmod +x scripts/backup.sh
```

### 2. Probar backup local

```bash
./scripts/backup.sh --local-only
```

El script detectarÃ¡ automÃ¡ticamente el contenedor de PostgreSQL y crearÃ¡ un backup en el directorio `backups/`.

### 3. Configurar la nube (opcional pero recomendado)

#### Instalar rclone

```bash
# OpciÃ³n 1: Script oficial (recomendado)
curl https://rclone.org/install.sh | sudo bash

# OpciÃ³n 2: Via apt (Debian/Ubuntu)
sudo apt install rclone
```

#### Configurar tu proveedor de nube

```bash
rclone config
```

**Para Google Drive:**
1. Escribe `n` para nuevo remote
2. Nombra el remote: `gdrive` (o el nombre que prefieras)
3. Selecciona `drive` (Google Drive)
4. **client_id**: dÃ©jalo vacÃ­o (enter)
5. **client_secret**: dÃ©jalo vacÃ­o (enter)
6. **scope**: selecciona `1` (full access)
7. **root_folder_id**: dÃ©jalo vacÃ­o
8. **service_account_file**: dÃ©jalo vacÃ­o
9. **Edit advanced config?**: `n`
10. **Use auto config?**: 
    - Si tienes acceso a un navegador: `y`
    - Si es un servidor sin GUI: `n` (te darÃ¡ un link para autorizar desde otra mÃ¡quina)
11. **Configure as team drive?**: `n`
12. Confirma con `y`

#### Verificar configuraciÃ³n

```bash
# Listar remotes configurados
rclone listremotes

# Probar conexiÃ³n (lista archivos en tu Drive)
rclone lsd gdrive:
```

### 4. Configurar backup automÃ¡tico diario

```bash
./scripts/backup.sh --setup-cron
```

Te preguntarÃ¡ a quÃ© hora quieres ejecutar el backup (0-23).

## ðŸ“– Uso del Script

### Ver ayuda

```bash
./scripts/backup.sh --help
```

### Ver estado de backups

```bash
./scripts/backup.sh --status
```

MostrarÃ¡:
- Backups locales (cantidad, tamaÃ±o, Ãºltimos 5)
- Estado de la nube (si rclone estÃ¡ configurado)
- Estado del cron job

### Ejecutar backup manual

```bash
# Backup completo (local + nube)
./scripts/backup.sh

# Solo backup local
./scripts/backup.sh --local-only
```

### Restaurar un backup

```bash
./scripts/backup.sh --restore
```

Te mostrarÃ¡ un menÃº con todos los backups disponibles y podrÃ¡s seleccionar cuÃ¡l restaurar.

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Variables de entorno

Puedes personalizar el comportamiento del script usando variables de entorno:

```bash
# Especificar contenedor de PostgreSQL manualmente
export POSTGRES_CONTAINER=mi-contenedor-db

# Cambiar usuario y base de datos
export POSTGRES_USER=mi_usuario
export POSTGRES_DB=mi_base_de_datos

# Cambiar remote de rclone
export RCLONE_REMOTE=dropbox

# Cambiar carpeta en la nube
export RCLONE_PATH=mis-backups-finanzas
```

### Cambiar retenciÃ³n de dÃ­as

Edita `scripts/backup.sh` y modifica:

```bash
BACKUP_RETENTION_DAYS=7  # Cambiar a 14, 30, etc.
```

### Cambiar horario del backup

Edita el cron job manualmente:

```bash
crontab -e
```

El formato es: `minuto hora dÃ­a-del-mes mes dÃ­a-de-semana`

Ejemplos:
```bash
# A las 3:00 AM todos los dÃ­as
0 3 * * * /ruta/a/backup.sh

# A las 2:30 AM todos los dÃ­as
30 2 * * * /ruta/a/backup.sh

# A la medianoche solo los domingos
0 0 * * 0 /ruta/a/backup.sh

# Dos veces al dÃ­a (3 AM y 3 PM)
0 3,15 * * * /ruta/a/backup.sh
```

## ðŸ”„ Proveedores de Nube Soportados

El script usa [rclone](https://rclone.org/), que soporta mÃ¡s de 40 proveedores de almacenamiento:

### Google Drive

```bash
rclone config
# Selecciona: drive
# Nombra el remote: gdrive
```

### Dropbox

```bash
rclone config
# Selecciona: dropbox
# Nombra el remote: dropbox
```

Luego: `export RCLONE_REMOTE=dropbox`

### Amazon S3 / Backblaze B2

```bash
rclone config
# Selecciona: s3 (para AWS) o b2 (para Backblaze)
# Configura las credenciales
```

### Servidor via SSH/SFTP

```bash
rclone config
# Selecciona: sftp
# Configura host, user, etc.
```

### NAS local (Synology, TrueNAS, etc.)

```bash
rclone config
# Selecciona: sftp o webdav segÃºn tu NAS
```

## ðŸ›¡ï¸ Recomendaciones de Seguridad

1. **MÃºltiples destinos**: Considera subir a 2 lugares (ej: Google Drive + NAS local)
2. **Monitoreo**: Revisa los logs periÃ³dicamente en `backups/backup.log`
3. **Pruebas de restauraciÃ³n**: Prueba restaurar un backup al menos una vez al mes
4. **Permisos**: AsegÃºrate de que solo tu usuario tenga acceso al directorio de backups

### Agregar notificaciones por Telegram (opcional)

1. Crea un bot con @BotFather en Telegram
2. ObtÃ©n tu chat_id
3. Agrega al final del script `backup.sh`:

```bash
send_telegram_notification() {
    local message="$1"
    local bot_token="TU_BOT_TOKEN"
    local chat_id="TU_CHAT_ID"
    curl -s -X POST "https://api.telegram.org/bot${bot_token}/sendMessage" \
        -d chat_id="${chat_id}" \
        -d text="${message}" \
        -d parse_mode="HTML" > /dev/null
}

# Llamar al final del main:
send_telegram_notification "âœ… Backup completado: $(basename $backup_file)"
```

## ðŸ“Š Estructura de Archivos

```
finanzas-pro/
â”œâ”€â”€ backups/
â”‚   â”œâ”€â”€ backup_20251222_030000.sql.gz
â”‚   â”œâ”€â”€ backup_20251221_030000.sql.gz
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ backup.log              # Logs del cron
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ backup.sh               # Script principal
â””â”€â”€ docs/
    â””â”€â”€ BACKUP_GUIDE.md         # Esta guÃ­a
```

## ðŸ†˜ Troubleshooting

### El backup falla con "contenedor no encontrado"

El script intenta detectar automÃ¡ticamente el contenedor. Si falla, especifÃ­calo manualmente:

```bash
# Ver contenedores disponibles
docker ps --format 'table {{.Names}}\t{{.Image}}'

# Especificar el contenedor
export POSTGRES_CONTAINER=nombre_del_contenedor
./scripts/backup.sh
```

### rclone dice "failed to authorize"

El token ha expirado. Re-autoriza:

```bash
rclone config reconnect gdrive:
```

### El cron no se ejecuta

1. Verifica que el cron estÃ© activo:
```bash
crontab -l
```

2. Revisa los logs:
```bash
tail -f backups/backup.log
```

3. Verifica permisos:
```bash
chmod +x scripts/backup.sh
```

### El backup estÃ¡ muy grande

Considera:
- Aumentar la compresiÃ³n (cambiar `gzip` por `gzip -9` en el script)
- Hacer backup solo de ciertas tablas
- Usar backup incremental

## ðŸ“ž Soporte

Si tienes problemas:
1. Revisa los logs en `backups/backup.log`
2. Ejecuta `./scripts/backup.sh --status` para ver el estado
3. Verifica permisos del script y directorio
4. Abre un issue en el repositorio del proyecto
